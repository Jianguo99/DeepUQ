{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "# from keras.backend.tensorflow_backend import set_session ## 和tf.keras不同\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "#0 是默认值，输出所有信息\n",
    "# 1 是屏蔽通知信息\n",
    "# 2 是屏蔽通知和警告信息\n",
    "###################################\n",
    "###########loading dataset#########\n",
    "###################################\n",
    "l_N = 60   # lengthscale对的数量\n",
    "k_ ='rbf'\n",
    "nx = 32\n",
    "ny = 32\n",
    "num_samples = 100   # 每个随机场采样的样本数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功！\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datadir = \"/home/huangjg/MyFiles/deep-uq-paper/data\"\n",
    "\n",
    "cellcentersFile = \"cellcenters_\"+\"nx_\"+str(nx)+\"_\"+str(ny)+\".pkl\"\n",
    "cellcenters = joblib.load(os.path.join(datadir,cellcentersFile))\n",
    "AllDataFile = k_+\"_l_N_\"+str(l_N)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\".pkl\"\n",
    "\n",
    "Train_all_data = joblib.load(os.path.join(datadir,AllDataFile))\n",
    "print(\"数据集加载成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本有 6144000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Input = []\n",
    "Output =[]\n",
    "for i in range(l_N):\n",
    "    for j in range(num_samples):\n",
    "        randomFiled_input = Train_all_data[i]['randomfield_sample'][j].reshape((1,-1))\n",
    "        outputs =Train_all_data[i]['outputs'][j].reshape((1,-1))\n",
    "        for k in range(nx*ny):\n",
    "            input = np.append(randomFiled_input,cellcenters[k])\n",
    "            Input.append(input)\n",
    "            Output.append(outputs[0,k])\n",
    "\n",
    "Inputs = np.array(Input)\n",
    "Input_Dim = Inputs.shape[1]\n",
    "labels = np.array(Output)\n",
    "print(\"训练样本有\",labels.shape[0])\n",
    "\n",
    "# train_mean_label = np.mean(labels,axis=0)\n",
    "# train_std_label = np.std(labels,axis=0)\n",
    "# print(train_mean_label )\n",
    "# print(train_std_label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump([train_mean_label,train_std_label],filename=\"norm_std.pkl\")\n",
    "train_mean_label,train_std_label = joblib.load(filename=\"norm_std.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/huangjg/MyFiles/deep-uq-paper/data/rbf_l_N_60_num_samples_100_nx_32_ny_32_train.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nrom_labels_train =  (labels-train_mean_label)/train_std_label\n",
    "print(nrom_labels_train.shape)\n",
    "TrainData = {\"Inputs\":Inputs,\n",
    "            \"labels\":nrom_labels_train,\n",
    "            \"normal\":[train_mean_label,train_std_label],}\n",
    "TrainDataFile = k_+\"_l_N_\"+str(l_N)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\"_train.pkl\"\n",
    "\n",
    "joblib.dump(TrainData,filename=os.path.join(datadir,TrainDataFile))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取lengthscale  作为训练任务标志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本有 (60, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/huangjg/MyFiles/deep-uq-paper/data/lengthscale_pair_array.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取出length scale\n",
    "\n",
    "lengthscale_pair_array = []\n",
    "for i in range(l_N):\n",
    "    lengthscale_pair_array.append(Train_all_data[i]['lengthscale_pair'])\n",
    "\n",
    "lengthscale_pair_array = np.array(lengthscale_pair_array)\n",
    "print(\"训练样本有\",lengthscale_pair_array.shape)\n",
    "joblib.dump(lengthscale_pair_array,filename=os.path.join(datadir,\"lengthscale_pair_array.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04031616, 0.51471225],\n",
       "       [0.4079415 , 0.23681085],\n",
       "       [0.06788817, 0.80069876],\n",
       "       [0.96598086, 0.11009247],\n",
       "       [0.31877116, 0.38358789],\n",
       "       [0.10932374, 0.90150841],\n",
       "       [0.78900085, 0.06676085],\n",
       "       [0.2290775 , 0.05234551],\n",
       "       [0.98914405, 0.12080711],\n",
       "       [0.66284873, 0.78377407],\n",
       "       [0.71095387, 0.37833149],\n",
       "       [0.87545583, 0.63759772],\n",
       "       [0.6962953 , 0.05039404],\n",
       "       [0.05579499, 0.46613041],\n",
       "       [0.78154703, 0.30716332],\n",
       "       [0.64799809, 0.77843295],\n",
       "       [0.75602611, 0.19179143],\n",
       "       [0.40386264, 0.27449089],\n",
       "       [0.61259102, 0.18466561],\n",
       "       [0.3849052 , 0.87286271],\n",
       "       [0.49678404, 0.27724455],\n",
       "       [0.48417573, 0.34920035],\n",
       "       [0.11754271, 0.27571643],\n",
       "       [0.49536241, 0.98122137],\n",
       "       [0.44409481, 0.10900082],\n",
       "       [0.73942936, 0.29883236],\n",
       "       [0.10329725, 0.20667263],\n",
       "       [0.55161422, 0.79806521],\n",
       "       [0.61012774, 0.264826  ],\n",
       "       [0.95364232, 0.51983881],\n",
       "       [0.26131556, 0.99755475],\n",
       "       [0.06924066, 0.98930204],\n",
       "       [0.71045215, 0.54249274],\n",
       "       [0.08672024, 0.449477  ],\n",
       "       [0.40487698, 0.45386728],\n",
       "       [0.41855842, 0.86217369],\n",
       "       [0.32731084, 0.51598897],\n",
       "       [0.30444904, 0.64006034],\n",
       "       [0.12677189, 0.07595598],\n",
       "       [0.0408007 , 0.58890812],\n",
       "       [0.10994429, 0.70503316],\n",
       "       [0.25565005, 0.21468263],\n",
       "       [0.85418076, 0.93646214],\n",
       "       [0.10489187, 0.62225328],\n",
       "       [0.56618274, 0.46866488],\n",
       "       [0.51175889, 0.95303108],\n",
       "       [0.75981085, 0.91109744],\n",
       "       [0.86495369, 0.18184007],\n",
       "       [0.34473118, 0.33148766],\n",
       "       [0.50097204, 0.27581719],\n",
       "       [0.21474356, 0.18806437],\n",
       "       [0.32657615, 0.38023147],\n",
       "       [0.38705271, 0.59910737],\n",
       "       [0.57213772, 0.33255968],\n",
       "       [0.09858269, 0.12818831],\n",
       "       [0.47329647, 0.20346445],\n",
       "       [0.61198504, 0.0383547 ],\n",
       "       [0.71562976, 0.1822431 ],\n",
       "       [0.22220656, 0.15891934],\n",
       "       [0.18235726, 0.54430717]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthscale_pair_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDataFile = k_+\"_l_N_\"+str(100)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\"_val.pkl\"\n",
    "\n",
    "Val_all_data = joblib.load(os.path.join(datadir,AllDataFile))\n",
    "print(\"数据集加载成功！例子数量为\",str(len(Val_all_data)))\n",
    "InputVal = []\n",
    "OutputVal =[]\n",
    "for i in tqdm(range(50)):\n",
    "    for j in range(num_samples):\n",
    "        randomFiled_input = Val_all_data[i]['randomfield_sample'][j].reshape((1,-1))\n",
    "        outputs =Val_all_data[i]['outputs'][j].reshape((1,-1))\n",
    "        for k in range(nx*ny):\n",
    "            input = np.append(randomFiled_input,cellcenters[k])\n",
    "            InputVal.append(input)\n",
    "            OutputVal.append(outputs[0,k])\n",
    "\n",
    "Inputs_Val = np.array(InputVal)\n",
    "labels_val = np.array(OutputVal)\n",
    "print(\"训练样本有\",labels_val.shape[0])\n",
    "norm_labels_val  = (labels_val-train_mean_label)/train_std_label\n",
    "print(norm_labels_val.shape)\n",
    "ValDtata=  {\n",
    "            \"normal\":[train_mean_label,train_std_label],\n",
    "            \"Inputs_val\":Inputs_Val,\n",
    "            \"labels_val\":norm_labels_val}\n",
    "\n",
    "\n",
    "ValDataFile = k_+\"_l_N_\"+str(l_N)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\"_val_pre50.pkl\"\n",
    "joblib.dump(ValDtata,filename=os.path.join(datadir,ValDataFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建元学习的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501192575295927 0.30546128200005446\n"
     ]
    }
   ],
   "source": [
    "train_mean_label,train_std_label = joblib.load(filename=\"norm_std.pkl\")\n",
    "print(train_mean_label,train_std_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:43<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/huangjg/MyFiles/deep-uq-paper/data/rbf_l_N_60_num_samples_100_nx_32_ny_32_train_meta.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "meta_Train_all_data = []\n",
    "for i in tqdm(range(l_N)):\n",
    "    Output = []\n",
    "    Input = []\n",
    "    for j in range(num_samples):\n",
    "        randomFiled_input = Train_all_data[i]['randomfield_sample'][j].reshape((1,-1))\n",
    "        outputs =Train_all_data[i]['outputs'][j].reshape((1,-1))\n",
    "        outputs  =  (outputs-train_mean_label)/train_std_label\n",
    "        for k in range(nx*ny):\n",
    "            input = np.append(randomFiled_input,cellcenters[k])\n",
    "            Input.append(input)\n",
    "            Output.append(outputs[0,k])\n",
    "    meta_task = {\"input\":Input,\n",
    "                \"labels\":Output,\n",
    "                \"lengthscale_pair\":Train_all_data[i][\"lengthscale_pair\"]}\n",
    "    meta_Train_all_data.append(meta_task)\n",
    "\n",
    "TrainDataFile = k_+\"_l_N_\"+str(l_N)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\"_train_meta.pkl\"\n",
    "\n",
    "joblib.dump(meta_Train_all_data,filename=os.path.join(datadir,TrainDataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataFile = k_+\"_l_N_\"+str(l_N)+\"_num_samples_\"+str(num_samples)+\\\n",
    "                    \"_nx_\"+str(nx)+\"_ny_\"+str(ny)+\"_train_meta.pkl\"\n",
    "\n",
    "lengthscale_array  =joblib.load(os.path.join(datadir,\"lengthscale_pair_array.pkl\"))\n",
    "meta_Train_all_data = joblib.load(os.path.join(datadir,TrainDataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "larray = []\n",
    "for i in range(60):\n",
    "    larray.append(meta_Train_all_data[i]['lengthscale_pair'])\n",
    "\n",
    "larray = np.array(larray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    if(larray[i] !=lengthscale_array[i]).any():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建高保真模型的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b76dcd71727825afe0829bad167819f070741296a55bd72c2defd8792205a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
